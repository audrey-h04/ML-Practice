{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b208d4-57c3-498d-8a40-441c6b41646d",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "The task is to build and train a classifier given a labeled dataset and then use it to infer the labels of a given unlabeled evaluation dataset. \n",
    "\n",
    "You will find the training and evaluation data on canvas.\n",
    "\n",
    "Here's the training data: TrainOnMe-2.csv \n",
    "\n",
    "Here's the evaluation data: EvaluateOnMe-2.csv \n",
    "\n",
    "Here's the ground truth: EvaluationGT-2.csv\n",
    "\n",
    "You can use whatever python libraries you like! The steps below are suggestions, but feel free to try any other techniques we discussed in class.\n",
    "\n",
    "You can submit the predicted labels by uploading them in csv format, which will then be compared to the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e3cf9a5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# For feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# For min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Some models you can try\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeca27-8629-4941-86c1-2d78c66ac582",
   "metadata": {},
   "source": [
    "## Load the training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c25826ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "df = pd.read_csv('TrainOnMe-2.csv') \n",
    "eval_df = pd.read_csv('EvaluateOnMe-2.csv')\n",
    "\n",
    "# Split your training dataset into features and labels - Audrey Updated\n",
    "X = df.drop(columns=['y'])  # Features (all columns except Labels which is 'y' column)\n",
    "y = df['y']  # Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc8de1-a994-4756-9989-d3f4b0de1f0d",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96ac15-16cc-4702-bbd1-a19cbc8d216c",
   "metadata": {},
   "source": [
    "#### Remove NA values and noise - edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c95776a-27af-4777-8128-a1e9abf94a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with invalid outputs:\n",
      "                                    Unnamed: 0               y       x1  \\\n",
      "307                                        306             NaN  1.12582   \n",
      "408                                        407             NaN  0.95125   \n",
      "581  Det är då som det stora vemodet rullar in             NaN      NaN   \n",
      "582            Och från havet blåser en isande   gråkall vind.      NaN   \n",
      "633                                        630             NaN  0.96981   \n",
      "739                                        736             NaN  0.61820   \n",
      "803          Den här är felt. Darfor erase it.             NaN      NaN   \n",
      "\n",
      "          x2       x3       x4        x5        x6                  x7  \\\n",
      "307  0.37246 -3.91978 -8.69740   9.94560   0.38929     Jerry Fernström   \n",
      "408 -0.14534  2.69299 -9.22679  10.24097  -0.15571  Erik Sven Williams   \n",
      "581      NaN      NaN      NaN       NaN       NaN                 NaN   \n",
      "582      NaN      NaN      NaN       NaN       NaN                 NaN   \n",
      "633 -0.05689  1.91173 -9.37374  10.64983  -0.17658  Erik Sven Williams   \n",
      "739  0.19933 -4.66957 -9.47122  10.15735   0.16653     Jerry Fernström   \n",
      "803      NaN      NaN      NaN       NaN       NaN                 NaN   \n",
      "\n",
      "          x8       x9       x10      x11    x12       x13  \n",
      "307 -0.74363 -0.25968  -8.27133 -0.92003  False  54.33097  \n",
      "408 -0.80408  1.80860 -10.72584 -1.75732   True  48.90877  \n",
      "581      NaN      NaN       NaN      NaN    NaN       NaN  \n",
      "582      NaN      NaN       NaN      NaN    NaN       NaN  \n",
      "633 -1.62071  0.69365  -5.43491 -0.35794   True  49.44661  \n",
      "739  0.30113 -0.11972  -9.79420 -2.45160  False  28.57539  \n",
      "803      NaN      NaN       NaN      NaN    NaN       NaN  \n",
      "Row indices removed due to invalid outputs: [307, 408, 581, 582, 633, 739, 803]\n",
      "Combined row indices removed: [739, 803, 581, 582, 307, 408, 633]\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the training set - edited\n",
    "train_copy = df.copy()\n",
    "feature_copy = X.copy()\n",
    "\n",
    "# 1: Removing the rows with y values that are not one of the four names\n",
    "# Force remove row 134\n",
    "df = df.drop(134) \n",
    "valid_y_outputs = ['Bob', 'Jorg', 'Shoogee', 'Atsuto']\n",
    "invalid_rows = df[~df['y'].isin(valid_y_outputs)]\n",
    "print(\"Rows with invalid outputs:\")\n",
    "print(invalid_rows)\n",
    "\n",
    "# Store row indices of invalid rows in a list\n",
    "removed_row_numbers = invalid_rows.index.tolist()\n",
    "print(\"Row indices removed due to invalid outputs:\", removed_row_numbers)\n",
    "\n",
    "# Remove the invalid rows from the DataFrame\n",
    "df_y = df[df['y'].isin(valid_y_outputs)]\n",
    "\n",
    "\n",
    "# 2: Remove rows that do not have a valid row number in the first column\n",
    "first_column_df = df_y.columns[0]\n",
    "\n",
    "# Convert to numeric, forcing errors to NaN, and then drop rows with NaN\n",
    "df_y.loc[:, first_column_df] = pd.to_numeric(df_y[first_column_df], errors='coerce')\n",
    "\n",
    "# Identify rows with non-numeric values in the first column\n",
    "non_numeric_rows = df_y[df_y[first_column_df].isna()]\n",
    "non_numeric_indices = non_numeric_rows.index.tolist()\n",
    "\n",
    "# Remove rows with non-numeric values\n",
    "df_0 = df_y.dropna(subset=[first_column_df])\n",
    "\n",
    "\n",
    "# 3: Removing the rows with missing values\n",
    "missing_rows = df_0[df_0.isnull().any(axis=1)]\n",
    "dropped_indices = missing_rows.index.tolist()\n",
    "df_cleaned = df_0.dropna()\n",
    "\n",
    "# Combine the list of removed indices\n",
    "combined_removed_rows = list(set(removed_row_numbers + dropped_indices + non_numeric_indices))\n",
    "print(\"Combined row indices removed:\", combined_removed_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882fd09e-b4b5-4856-9ab0-0b4916e461e9",
   "metadata": {},
   "source": [
    "#### Check the dtypes of all features - edited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c53e4536-7b82-488c-b0cd-e02caf5fd1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     object\n",
      "y              object\n",
      "x1            float64\n",
      "x2            float64\n",
      "x3            float64\n",
      "x4            float64\n",
      "x5            float64\n",
      "x6             object\n",
      "x7             object\n",
      "x8            float64\n",
      "x9            float64\n",
      "x10           float64\n",
      "x11           float64\n",
      "x12            object\n",
      "x13           float64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1003 entries, 0 to 1003\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1003 non-null   object \n",
      " 1   y           997 non-null    object \n",
      " 2   x1          1000 non-null   float64\n",
      " 3   x2          1000 non-null   float64\n",
      " 4   x3          1000 non-null   float64\n",
      " 5   x4          1000 non-null   float64\n",
      " 6   x5          1000 non-null   float64\n",
      " 7   x6          1000 non-null   object \n",
      " 8   x7          1000 non-null   object \n",
      " 9   x8          1000 non-null   float64\n",
      " 10  x9          1000 non-null   float64\n",
      " 11  x10         1000 non-null   float64\n",
      " 12  x11         1000 non-null   float64\n",
      " 13  x12         1000 non-null   object \n",
      " 14  x13         1000 non-null   float64\n",
      "dtypes: float64(10), object(5)\n",
      "memory usage: 125.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the dtypes of all features - edited \n",
    "print(df.dtypes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27937b-0ad8-4e49-ab75-1a0400499d17",
   "metadata": {},
   "source": [
    "#### Convert text columns to category - edited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f66da102-5ff1-497b-bf82-046f6f4caf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'x7': 0\n",
      "Rows with non-numeric values in 'x6':\n",
      "    Unnamed: 0     y       x1       x2       x3       x4        x5  x6  \\\n",
      "265        264  Jorg  0.88362  0.12864 -4.91248 -9.41917  10.04934 NaN   \n",
      "\n",
      "          x8      x9      x10      x11  x12       x13  x7_Erik Sven Williams  \\\n",
      "265  0.60795  2.3159 -5.25392 -1.40652    0  41.72493                    0.0   \n",
      "\n",
      "     x7_Jerry Fernström  x7_Jerry Williams  x7_Jerry från Solna  \n",
      "265                 1.0                0.0                  0.0  \n",
      "Unnamed: 0                 int64\n",
      "y                         object\n",
      "x1                       float64\n",
      "x2                       float64\n",
      "x3                       float64\n",
      "x4                       float64\n",
      "x5                       float64\n",
      "x6                       float64\n",
      "x8                       float64\n",
      "x9                       float64\n",
      "x10                      float64\n",
      "x11                      float64\n",
      "x12                        int64\n",
      "x13                      float64\n",
      "x7_Erik Sven Williams    float64\n",
      "x7_Jerry Fernström       float64\n",
      "x7_Jerry Williams        float64\n",
      "x7_Jerry från Solna      float64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 996 entries, 0 to 1003\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             996 non-null    int64  \n",
      " 1   y                      996 non-null    object \n",
      " 2   x1                     996 non-null    float64\n",
      " 3   x2                     996 non-null    float64\n",
      " 4   x3                     996 non-null    float64\n",
      " 5   x4                     996 non-null    float64\n",
      " 6   x5                     996 non-null    float64\n",
      " 7   x6                     996 non-null    float64\n",
      " 8   x8                     996 non-null    float64\n",
      " 9   x9                     996 non-null    float64\n",
      " 10  x10                    996 non-null    float64\n",
      " 11  x11                    996 non-null    float64\n",
      " 12  x12                    996 non-null    int64  \n",
      " 13  x13                    996 non-null    float64\n",
      " 14  x7_Erik Sven Williams  996 non-null    float64\n",
      " 15  x7_Jerry Fernström     996 non-null    float64\n",
      " 16  x7_Jerry Williams      996 non-null    float64\n",
      " 17  x7_Jerry från Solna    996 non-null    float64\n",
      "dtypes: float64(15), int64(2), object(1)\n",
      "memory usage: 147.8+ KB\n",
      "Non-numeric columns: Index(['y'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_23032\\1365482065.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['x6'].fillna(df_cleaned['x6'].median(), inplace=True)\n",
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_23032\\1365482065.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[df_cleaned.columns[0]].fillna(median_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the 'x7' column\n",
    "print(\"Missing values in 'x7':\", df_cleaned['x7'].isna().sum())\n",
    "\n",
    "# Drop rows with missing values in 'x7'\n",
    "df_cleaned = df_cleaned.dropna(subset=['x7'])\n",
    "\n",
    "# Convert the x7 column using OneHotEncoder\n",
    "x7_cat = df_cleaned[['x7']]\n",
    "x7_cat_encoder = OneHotEncoder(sparse_output=False, drop='first')  \n",
    "x7_encoded = x7_cat_encoder.fit_transform(x7_cat)\n",
    "x7_encoded_df = pd.DataFrame(x7_encoded, columns=x7_cat_encoder.get_feature_names_out(['x7'])) \n",
    "\n",
    "# Ensure the index lengths match before assigning\n",
    "if len(x7_encoded_df) == len(df_cleaned):\n",
    "    x7_encoded_df.index = df_cleaned.index  # Reset the index to match the original DataFrame\n",
    "else:\n",
    "    print(\"Warning: Mismatch in the number of rows after encoding 'x7'\")\n",
    "\n",
    "# Drop the original 'x7' column and concatenate the encoded columns\n",
    "df_cleaned = df_cleaned.drop('x7', axis=1)\n",
    "df_cleaned = pd.concat([df_cleaned, x7_encoded_df], axis=1)\n",
    "\n",
    "# Convert the x12 column\n",
    "df_cleaned['x12'] = df_cleaned['x12'].astype(int)  # Convert True/False column to 1's and 0's\n",
    "\n",
    "# Attempt to convert x6 to numeric, coercing errors to NaN\n",
    "df_cleaned['x6'] = pd.to_numeric(df_cleaned['x6'], errors='coerce')\n",
    "# Check if there are any NaN values after the conversion\n",
    "non_numeric_x6 = df_cleaned[df_cleaned['x6'].isna()]\n",
    "print(\"Rows with non-numeric values in 'x6':\")\n",
    "print(non_numeric_x6)\n",
    "# Fill in non-numeric x6\n",
    "df_cleaned['x6'].fillna(df_cleaned['x6'].median(), inplace=True)\n",
    "\n",
    "# Convert the first column to numeric, coercing errors to NaN\n",
    "df_cleaned[df_cleaned.columns[0]] = pd.to_numeric(df_cleaned[df_cleaned.columns[0]], errors='coerce')\n",
    "# Compute the median of the column, ignoring NaN values\n",
    "median_value = df_cleaned[df_cleaned.columns[0]].median()\n",
    "# Fill NaN values with the median value\n",
    "df_cleaned[df_cleaned.columns[0]].fillna(median_value, inplace=True)\n",
    "\n",
    "# Check the types and information of the DataFrame\n",
    "print(df_cleaned.dtypes)\n",
    "df_cleaned.info()\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_cols = df_cleaned.select_dtypes(exclude=[np.number]).columns\n",
    "print(f\"Non-numeric columns: {non_numeric_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa58bb",
   "metadata": {},
   "source": [
    "### Convert Eval columns to categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0f54a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      int64\n",
      "x1            float64\n",
      "x2            float64\n",
      "x3            float64\n",
      "x4            float64\n",
      "x5            float64\n",
      "x6            float64\n",
      "x7             object\n",
      "x8            float64\n",
      "x9            float64\n",
      "x10           float64\n",
      "x11           float64\n",
      "x12              bool\n",
      "x13           float64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  10000 non-null  int64  \n",
      " 1   x1          10000 non-null  float64\n",
      " 2   x2          10000 non-null  float64\n",
      " 3   x3          10000 non-null  float64\n",
      " 4   x4          10000 non-null  float64\n",
      " 5   x5          10000 non-null  float64\n",
      " 6   x6          10000 non-null  float64\n",
      " 7   x7          10000 non-null  object \n",
      " 8   x8          10000 non-null  float64\n",
      " 9   x9          10000 non-null  float64\n",
      " 10  x10         10000 non-null  float64\n",
      " 11  x11         10000 non-null  float64\n",
      " 12  x12         10000 non-null  bool   \n",
      " 13  x13         10000 non-null  float64\n",
      "dtypes: bool(1), float64(11), int64(1), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the dtypes of all features - edited \n",
    "print(eval_df.dtypes)\n",
    "eval_df.info()\n",
    "\n",
    "# Convert the eval x7 column using OneHotEncoder\n",
    "eval_x7_cat = eval_df[['x7']]\n",
    "eval_x7_cat_encoder = OneHotEncoder(sparse_output=False, drop='first')  \n",
    "eval_x7_encoded = eval_x7_cat_encoder.fit_transform(eval_x7_cat)\n",
    "eval_x7_encoded_df = pd.DataFrame(eval_x7_encoded, columns=eval_x7_cat_encoder.get_feature_names_out(['x7'])) \n",
    "\n",
    "# Drop the original 'x7' column and concatenate the encoded columns\n",
    "eval_df = eval_df.drop('x7', axis=1)\n",
    "eval_df = pd.concat([eval_df, eval_x7_encoded_df], axis=1)\n",
    "\n",
    "# Convert the x12 column\n",
    "eval_df['x12'] = eval_df['x12'].astype(int)  # Convert True/False column to 1's and 0's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b8cf7",
   "metadata": {},
   "source": [
    "#### Check types have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de15d0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x8', 'x9', 'x10',\n",
      "       'x11', 'x12', 'x13', 'x7_Erik Sven Williams', 'x7_Jerry Fernström',\n",
      "       'x7_Jerry Williams', 'x7_Jerry från Solna'],\n",
      "      dtype='object')\n",
      "Unnamed: 0                 int64\n",
      "x1                       float64\n",
      "x2                       float64\n",
      "x3                       float64\n",
      "x4                       float64\n",
      "x5                       float64\n",
      "x6                       float64\n",
      "x8                       float64\n",
      "x9                       float64\n",
      "x10                      float64\n",
      "x11                      float64\n",
      "x12                        int64\n",
      "x13                      float64\n",
      "x7_Erik Sven Williams    float64\n",
      "x7_Jerry Fernström       float64\n",
      "x7_Jerry Williams        float64\n",
      "x7_Jerry från Solna      float64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             10000 non-null  int64  \n",
      " 1   x1                     10000 non-null  float64\n",
      " 2   x2                     10000 non-null  float64\n",
      " 3   x3                     10000 non-null  float64\n",
      " 4   x4                     10000 non-null  float64\n",
      " 5   x5                     10000 non-null  float64\n",
      " 6   x6                     10000 non-null  float64\n",
      " 7   x8                     10000 non-null  float64\n",
      " 8   x9                     10000 non-null  float64\n",
      " 9   x10                    10000 non-null  float64\n",
      " 10  x11                    10000 non-null  float64\n",
      " 11  x12                    10000 non-null  int64  \n",
      " 12  x13                    10000 non-null  float64\n",
      " 13  x7_Erik Sven Williams  10000 non-null  float64\n",
      " 14  x7_Jerry Fernström     10000 non-null  float64\n",
      " 15  x7_Jerry Williams      10000 non-null  float64\n",
      " 16  x7_Jerry från Solna    10000 non-null  float64\n",
      "dtypes: float64(15), int64(2)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Check types of eval have changed\n",
    "print(eval_df.columns)\n",
    "print(eval_df.dtypes)\n",
    "eval_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad60bf-a533-4340-aabb-3d7a5c466e61",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "## Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ccf3fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with outliers:\n",
      "     Unnamed: 0        y       x1       x2        x3            x4        x5  \\\n",
      "27           27     Jorg  2.10221  1.56680  -4.65063 -9.084660e+00  10.62068   \n",
      "40           40      Bob  1.34002  1.83351  -3.68605 -8.389370e+00  10.48468   \n",
      "55           55     Jorg  1.99826  0.05477  -0.98095 -9.344060e+00   9.92647   \n",
      "64           64      Bob  3.00284  1.45413 -11.15675 -9.381620e+00   9.92228   \n",
      "82           82  Shoogee -0.10483  1.87380   0.76205 -9.500880e+00   9.94529   \n",
      "146         145     Jorg  1.06445  0.70250  -0.68295 -9.645790e+00  10.08945   \n",
      "220         219     Jorg  0.86135 -0.10248   0.47975 -9.133260e+00  10.45166   \n",
      "250         249  Shoogee -0.71322 -2.00360  -0.68410 -9.951670e+00  10.04280   \n",
      "269         268     Jorg  4.00674 -0.14577  -5.37766 -9.081050e+00  10.44582   \n",
      "281         280     Jorg  1.10084 -0.61411   0.50381 -9.234500e+00  10.24072   \n",
      "346         345      Bob  1.92895  0.20643  -3.61880 -8.928800e+00  10.10618   \n",
      "402         401     Jorg  1.09771 -0.95094  -2.16548 -9.154530e+00   9.87695   \n",
      "420         419      Bob  1.93965  1.55338  -1.80559 -8.712710e+00  10.54265   \n",
      "439         438     Jorg  1.90702  1.51831  -0.30460 -9.278480e+00   9.93242   \n",
      "454         453     Jorg -0.74379 -0.54319  -0.66926 -9.363460e+00   9.97776   \n",
      "457         456     Jorg  0.23091  0.28698   3.40777 -8.947520e+00  10.46223   \n",
      "493         492     Jorg  1.11905 -0.10776   1.40236 -9.048340e+00  10.25638   \n",
      "529         528      Bob  0.94251 -0.92197  -7.75000 -9.646170e+00  10.78068   \n",
      "542         541     Jorg  1.05665  0.12999   2.39233 -9.315100e+00   9.91187   \n",
      "571         570  Shoogee  1.23657 -1.00589 -11.98567 -9.252180e+00  10.32846   \n",
      "610         607  Shoogee  1.58244  0.90592  -0.53531 -8.901300e+00   9.89282   \n",
      "615         612      Bob  0.66391 -0.44748  -4.92971 -8.534770e+00  10.67401   \n",
      "627         624     Jorg  2.49408  1.63768   1.21051 -8.947890e+00  10.43927   \n",
      "663         660     Jorg  1.29429  1.54700  -1.13066 -8.978130e+00  10.60300   \n",
      "685         682  Shoogee  2.44501  1.76895  -2.03006 -8.631390e+00   9.95940   \n",
      "745         742  Shoogee  2.00250  1.74151  -4.80911 -9.817200e+00  10.73249   \n",
      "779         776  Shoogee  2.35470  1.54871  -7.12908 -9.788520e+00  10.45469   \n",
      "781         778      Bob  1.86750  1.84514  -6.42226 -8.830920e+00   9.86563   \n",
      "783         780  Shoogee  2.03401 -0.06649   8.71736 -9.267180e+00  10.64393   \n",
      "792         789      Bob  1.34546  1.53722   1.11632 -8.601590e+00  10.41378   \n",
      "813         809      Bob  1.06262  0.84316   8.74336 -9.449060e+00   9.90808   \n",
      "851         847     Jorg  1.89688  0.67813  -1.38989 -9.000000e+07  10.35667   \n",
      "883         879      Bob -0.25435  0.04663   2.76534 -9.266200e+00  10.83739   \n",
      "901         897     Jorg  1.10272  1.67138  -2.51251 -9.081460e+00  10.57308   \n",
      "911         907  Shoogee  1.09733  1.74962  -1.24958 -8.842910e+00  10.09565   \n",
      "912         908     Jorg  1.12554  0.03888  -1.39053 -9.311560e+00  10.60889   \n",
      "937         933     Jorg  0.73113 -2.09131  -2.59491 -8.839240e+00  10.42306   \n",
      "977         973      Bob  1.98672  1.50288   2.85848 -9.669120e+00  10.18651   \n",
      "\n",
      "          x6       x8       x9       x10           x11  x12        x13  \\\n",
      "27   1.48611 -0.49905  0.66664  -9.35286  3.794500e-01    0  102.78509   \n",
      "40   1.82237  0.59596  0.24433  -9.32241 -1.094000e+00    0   65.15790   \n",
      "55   0.02918 -0.16430  1.33853 -10.56711  1.000000e+21    0   99.42258   \n",
      "64   1.48189  3.10176 -1.49886  -8.60334 -4.396020e+00    0  144.56380   \n",
      "82   1.94928  0.54862 -1.27956  -8.11025 -8.038500e-01    1   -4.86069   \n",
      "146  0.74737 -4.52421 -2.43958 -11.30639  3.509830e+00    1   52.88081   \n",
      "220 -0.12868 -5.27155 -1.10172  -7.47194 -1.825130e+00    1   43.30750   \n",
      "250 -2.11592 -0.67337 -1.24283 -11.92288  6.126000e-01    0  -36.00330   \n",
      "269 -0.04032 -2.31061 -1.26020  -8.07410 -2.676090e+00    0  197.64810   \n",
      "281 -0.64155  0.47555  0.31357 -13.90486  2.525270e+00    0   55.29389   \n",
      "346 -0.00121 -0.70699  4.27446 -10.42693 -8.594500e-01    0   94.63787   \n",
      "402 -0.94268 -4.37889 -3.66414  -6.33620 -1.217050e+00    0   53.80255   \n",
      "420  1.71695  0.29213 -1.20297  -8.72820 -4.633270e+00    0   96.07963   \n",
      "439  1.60863  0.67116  0.91019  -6.36718 -1.772660e+00    1   95.19890   \n",
      "454 -0.54978  0.22429  4.35974  -9.51067 -8.851600e-01    0  -37.52411   \n",
      "457  0.25518  1.57165 -4.53221  -8.97569 -1.720110e+00    1   13.24955   \n",
      "493 -0.14926 -4.16516 -0.84975 -10.13742 -1.974170e+00    1   56.65354   \n",
      "529 -0.96374  4.03819 -3.38391 -10.97575 -3.434810e+00    0   43.25031   \n",
      "542  0.14743  3.24249  4.81384 -10.36584  2.414400e-01    1   54.02889   \n",
      "571 -1.04070  0.05583  0.96990  -7.94936 -3.882900e-01    0   55.83542   \n",
      "610  0.96077 -0.27749 -0.30855  -3.20119 -3.854340e+00    1   78.85436   \n",
      "615 -0.59958  2.32468 -5.25976  -8.45420 -2.411920e+00    0   30.73049   \n",
      "627  1.56433 -2.15154  0.88104  -9.95340 -8.723000e-02    1  125.30901   \n",
      "663  1.63545 -0.28580 -1.00081 -10.30337  1.545100e-01    1   64.14931   \n",
      "685  1.78216  1.18191 -2.50447  -5.15546 -1.640260e+00    0  121.23555   \n",
      "745  1.73998 -0.11862  1.71738  -8.87378 -3.533300e-01    0   97.72051   \n",
      "779  1.62955  1.09596 -1.05366 -10.51599 -2.994600e-01    0  114.17056   \n",
      "781  1.72060 -2.94152  1.75002  -9.71918 -2.737230e+00    0   90.16376   \n",
      "783 -0.40979  0.72325 -0.28806  -9.14663  1.388600e-01    1  106.05936   \n",
      "792  1.53784  0.59191  0.85441  -8.56240 -1.928230e+00    1   67.83118   \n",
      "813  0.73247 -3.31198  1.47798 -10.32635 -1.454210e+00    1   57.50276   \n",
      "851  0.87336  1.24007 -2.37838  -7.60572 -2.107290e+00    0   94.14893   \n",
      "883 -0.04599 -4.67201  2.00775 -10.07769 -2.194410e+00    1  -11.33461   \n",
      "901  1.70885 -1.93356 -2.97917 -11.42192  2.820490e+00    0   53.87975   \n",
      "911  1.90330 -0.00249  1.12695  -6.02003 -1.797540e+00    1   54.24171   \n",
      "912  0.08899 -4.13059 -2.59098 -14.57144  3.962000e+00    0   55.58152   \n",
      "937 -2.09736 -1.80389  0.00761 -11.42454 -8.052600e-01    0   35.25884   \n",
      "977  1.53703 -0.45059  0.36376 -10.23832 -1.594080e+00    1  100.76528   \n",
      "\n",
      "     x7_Erik Sven Williams  x7_Jerry Fernström  x7_Jerry Williams  \\\n",
      "27                     0.0                 0.0                1.0   \n",
      "40                     0.0                 0.0                1.0   \n",
      "55                     0.0                 1.0                0.0   \n",
      "64                     0.0                 0.0                0.0   \n",
      "82                     0.0                 0.0                1.0   \n",
      "146                    0.0                 1.0                0.0   \n",
      "220                    1.0                 0.0                0.0   \n",
      "250                    0.0                 0.0                0.0   \n",
      "269                    1.0                 0.0                0.0   \n",
      "281                    1.0                 0.0                0.0   \n",
      "346                    0.0                 1.0                0.0   \n",
      "402                    0.0                 0.0                0.0   \n",
      "420                    0.0                 0.0                1.0   \n",
      "439                    0.0                 0.0                1.0   \n",
      "454                    1.0                 0.0                0.0   \n",
      "457                    0.0                 1.0                0.0   \n",
      "493                    1.0                 0.0                0.0   \n",
      "529                    0.0                 0.0                0.0   \n",
      "542                    0.0                 1.0                0.0   \n",
      "571                    0.0                 0.0                0.0   \n",
      "610                    0.0                 0.0                0.0   \n",
      "615                    1.0                 0.0                0.0   \n",
      "627                    0.0                 0.0                1.0   \n",
      "663                    0.0                 0.0                1.0   \n",
      "685                    0.0                 0.0                1.0   \n",
      "745                    0.0                 0.0                1.0   \n",
      "779                    0.0                 0.0                1.0   \n",
      "781                    0.0                 0.0                1.0   \n",
      "783                    1.0                 0.0                0.0   \n",
      "792                    0.0                 0.0                1.0   \n",
      "813                    0.0                 0.0                0.0   \n",
      "851                    0.0                 1.0                0.0   \n",
      "883                    0.0                 1.0                0.0   \n",
      "901                    0.0                 0.0                1.0   \n",
      "911                    0.0                 0.0                1.0   \n",
      "912                    0.0                 1.0                0.0   \n",
      "937                    0.0                 0.0                0.0   \n",
      "977                    0.0                 0.0                1.0   \n",
      "\n",
      "     x7_Jerry från Solna  \n",
      "27                   0.0  \n",
      "40                   0.0  \n",
      "55                   0.0  \n",
      "64                   0.0  \n",
      "82                   0.0  \n",
      "146                  0.0  \n",
      "220                  0.0  \n",
      "250                  1.0  \n",
      "269                  0.0  \n",
      "281                  0.0  \n",
      "346                  0.0  \n",
      "402                  1.0  \n",
      "420                  0.0  \n",
      "439                  0.0  \n",
      "454                  0.0  \n",
      "457                  0.0  \n",
      "493                  0.0  \n",
      "529                  1.0  \n",
      "542                  0.0  \n",
      "571                  1.0  \n",
      "610                  0.0  \n",
      "615                  0.0  \n",
      "627                  0.0  \n",
      "663                  0.0  \n",
      "685                  0.0  \n",
      "745                  0.0  \n",
      "779                  0.0  \n",
      "781                  0.0  \n",
      "783                  0.0  \n",
      "792                  0.0  \n",
      "813                  0.0  \n",
      "851                  0.0  \n",
      "883                  0.0  \n",
      "901                  0.0  \n",
      "911                  0.0  \n",
      "912                  0.0  \n",
      "937                  1.0  \n",
      "977                  0.0  \n",
      "\n",
      "DataFrame after removing outliers:\n",
      "      Unnamed: 0        y       x1       x2       x3       x4        x5  \\\n",
      "0              0  Shoogee  2.20274 -0.04690 -4.69816 -9.07800  10.13118   \n",
      "1              1      Bob  2.01516 -0.12177 -4.24286 -9.79772   9.98259   \n",
      "2              2      Bob  0.02598 -0.24764  0.39977 -9.54167  10.53391   \n",
      "3              3     Jorg  0.39778 -0.83343 -2.14272 -9.06550  10.15047   \n",
      "4              4     Jorg  1.25346  0.09320  1.54063 -9.33171   9.92016   \n",
      "...          ...      ...      ...      ...      ...      ...       ...   \n",
      "999          995  Shoogee  2.96657  0.44602 -6.39121 -8.92726  10.59103   \n",
      "1000         996  Shoogee  0.20434 -0.67408 -4.12029 -9.00304  10.36168   \n",
      "1001         997     Jorg  0.72078  0.74335 -0.63288 -8.94255  10.07998   \n",
      "1002         998     Jorg  0.34186  0.10278 -0.39189 -9.05518   9.98665   \n",
      "1003         999     Jorg  0.57296 -0.40369 -1.73764 -9.01203   9.86515   \n",
      "\n",
      "           x6       x8       x9       x10      x11  x12        x13  \\\n",
      "0    -0.08900  0.54191  0.52041  -5.66990 -0.93831    0  107.78776   \n",
      "1    -0.01485 -1.21671  1.18749  -9.25300 -1.21892    0   98.63633   \n",
      "2    -0.27978 -2.39764  1.95167  -9.46447 -2.68910    1    1.49880   \n",
      "3    -0.84583  0.09768  0.92010 -11.17952  0.59877    0   18.81785   \n",
      "4     0.09889 -0.46134  0.16381 -12.07755  1.09106    1   63.44326   \n",
      "...       ...      ...      ...       ...      ...  ...        ...   \n",
      "999   0.38746  0.69268 -0.58989 -10.53091  0.20014    0  145.13294   \n",
      "1000 -0.60313  0.22119 -1.57906  -9.80819 -2.42307    0    8.15681   \n",
      "1001  0.82252  1.49456  2.23215  -7.26243  0.69045    1   35.72234   \n",
      "1002  0.04969 -0.25843  0.24975  -9.88372  0.47915    0   16.89682   \n",
      "1003 -0.39589  1.32041  0.94174  -6.46244  0.50173    0   27.77929   \n",
      "\n",
      "      x7_Erik Sven Williams  x7_Jerry Fernström  x7_Jerry Williams  \\\n",
      "0                       1.0                 0.0                0.0   \n",
      "1                       1.0                 0.0                0.0   \n",
      "2                       1.0                 0.0                0.0   \n",
      "3                       0.0                 0.0                0.0   \n",
      "4                       0.0                 1.0                0.0   \n",
      "...                     ...                 ...                ...   \n",
      "999                     0.0                 1.0                0.0   \n",
      "1000                    1.0                 0.0                0.0   \n",
      "1001                    0.0                 1.0                0.0   \n",
      "1002                    0.0                 1.0                0.0   \n",
      "1003                    1.0                 0.0                0.0   \n",
      "\n",
      "      x7_Jerry från Solna  \n",
      "0                     0.0  \n",
      "1                     0.0  \n",
      "2                     0.0  \n",
      "3                     1.0  \n",
      "4                     0.0  \n",
      "...                   ...  \n",
      "999                   0.0  \n",
      "1000                  0.0  \n",
      "1001                  0.0  \n",
      "1002                  0.0  \n",
      "1003                  0.0  \n",
      "\n",
      "[958 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure you only use numeric columns for Z-score calculation\n",
    "numeric_df = df_cleaned.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate Z-scores for each column in df_cleaned, which ensures index alignment\n",
    "z_scores = np.abs(stats.zscore(numeric_df))\n",
    "\n",
    "# Define a threshold for Z-scores\n",
    "z_threshold = 3\n",
    "\n",
    "# Identify rows that have any Z-score above the threshold\n",
    "outliers = (z_scores > z_threshold).any(axis=1)\n",
    "\n",
    "# Ensure the index of 'outliers' matches df_cleaned\n",
    "outliers = outliers.reindex(df_cleaned.index, fill_value=False)\n",
    "\n",
    "# Print the rows with outliers\n",
    "outlier_rows = df_cleaned[outliers]\n",
    "print(\"Rows with outliers:\")\n",
    "print(outlier_rows)\n",
    "\n",
    "# Remove outliers from df_cleaned\n",
    "df_cleaned = df_cleaned[~outliers]\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(\"\\nDataFrame after removing outliers:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "# There are different ways to do this but one way could be to use stats.zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933a70d-7f5c-46cf-b278-536053c42322",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a5a446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means of scaled features:\n",
      "Unnamed: 0               0.000000e+00\n",
      "x1                       3.337622e-17\n",
      "x2                       1.483388e-17\n",
      "x3                       2.039658e-17\n",
      "x4                      -2.117536e-15\n",
      "x5                       4.031106e-15\n",
      "x6                      -3.708469e-17\n",
      "x8                       2.225082e-17\n",
      "x9                       1.668811e-17\n",
      "x10                     -5.562704e-17\n",
      "x11                     -7.416939e-17\n",
      "x12                     -3.893893e-17\n",
      "x13                     -9.271173e-18\n",
      "x7_Erik Sven Williams   -7.046092e-17\n",
      "x7_Jerry Fernström       5.701772e-17\n",
      "x7_Jerry Williams        0.000000e+00\n",
      "x7_Jerry från Solna     -2.595929e-17\n",
      "dtype: float64\n",
      "\n",
      "Standard deviations of scaled features:\n",
      "Unnamed: 0               1.000522\n",
      "x1                       1.000522\n",
      "x2                       1.000522\n",
      "x3                       1.000522\n",
      "x4                       1.000522\n",
      "x5                       1.000522\n",
      "x6                       1.000522\n",
      "x8                       1.000522\n",
      "x9                       1.000522\n",
      "x10                      1.000522\n",
      "x11                      1.000522\n",
      "x12                      1.000522\n",
      "x13                      1.000522\n",
      "x7_Erik Sven Williams    1.000522\n",
      "x7_Jerry Fernström       1.000522\n",
      "x7_Jerry Williams        0.000000\n",
      "x7_Jerry från Solna      1.000522\n",
      "dtype: float64\n",
      "Non-numeric columns: Index(['y'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Scale your features\n",
    "# You can try both standardscaler and minmaxscaler and see which works better - edited\n",
    "# ONLY USE NUMERICAL\n",
    "data_num = df_cleaned.select_dtypes(include=['number']) \n",
    "std_scaler = StandardScaler()\n",
    "data_num_std_scaled = std_scaler.fit_transform(data_num)\n",
    "\n",
    "# Test if Standard Scaled worked\n",
    "scaled_df = pd.DataFrame(data_num_std_scaled, columns=data_num.columns, index=df_cleaned.index)\n",
    "\n",
    "# Check mean and standard deviation\n",
    "means = scaled_df.mean()\n",
    "std_devs = scaled_df.std()\n",
    "\n",
    "print(\"Means of scaled features:\")\n",
    "print(means)\n",
    "print(\"\\nStandard deviations of scaled features:\")\n",
    "print(std_devs)\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_cols = df_cleaned.select_dtypes(exclude=[np.number]).columns\n",
    "print(f\"Non-numeric columns: {non_numeric_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f9ee0-f87c-4750-a328-dbdc9071fb07",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c62b35ae-3de7-4044-a59f-831a519ba36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could try to apply SelectKBest class to extract the most useful features (this is optional but MIGHT improve accuracy)\n",
    "# Remove whichever features that are not useful\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1dcc6-5f53-478d-9660-95368b4db961",
   "metadata": {},
   "source": [
    "## Split your data to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ed4f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['y'], dtype='object')\n",
      "Non-numeric columns in X_train: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric columns\n",
    "non_numeric_cols = df_cleaned.select_dtypes(exclude=[np.number]).columns\n",
    "print(f\"Non-numeric columns: {non_numeric_cols}\")\n",
    "\n",
    "X = df_cleaned.drop(columns=['y'])  # Drop the target column to get features\n",
    "y= df_cleaned['y']  # Extract the target variable\n",
    "\n",
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state = 0)\n",
    "\n",
    "# Check for non-numeric columns in X_train\n",
    "non_numeric_columns = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "print(\"Non-numeric columns in X_train:\", non_numeric_columns)\n",
    "\n",
    "# Check for non-numeric values in each column\n",
    "for col in X_train.columns:\n",
    "    non_numeric = X_train[X_train[col].apply(lambda x: not isinstance(x, (int, float)))]\n",
    "    if not non_numeric.empty:\n",
    "        print(f\"Non-numeric values in column {col}:\")\n",
    "        print(non_numeric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cbcb0-c8ff-4d43-ab10-6c1e7d3aa0be",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "* You can try models other than the models listed below\n",
    "* You can try different hyperparameters\n",
    "* Evaluate your model using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c68ffb0a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4479166666666667\n",
      "0.46 accuracy with a standard deviation of 0.14\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# Try linear SVM classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "linear = LinearSVC(C=0.5).fit(X_train, y_train)\n",
    "print(linear.score(X_test,y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(linear,X_test,y_test,cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d53115ce",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.45 accuracy with a standard deviation of 0.15\n"
     ]
    }
   ],
   "source": [
    "#Try decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion = \"gini\").fit(X_train, y_train)\n",
    "print(decision_tree.score(X_test,y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(decision_tree,X_test,y_test,cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01507d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6041666666666666\n",
      "0.53 accuracy with a standard deviation of 0.14\n"
     ]
    }
   ],
   "source": [
    "#Try random forest classifier\n",
    "random_forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "print(random_forest.score(X_test,y_test))\n",
    "\n",
    "scores = cross_val_score(random_forest,X_test,y_test,cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b68b7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jorg' 'Bob' 'Jorg' ... 'Jorg' 'Bob' 'Jorg']\n"
     ]
    }
   ],
   "source": [
    "# Use your best model to predict the labels for the evaluation set\n",
    "best_model = random_forest\n",
    "y_pred = best_model.predict(eval_df)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6eb50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your predictions to a csv and upload it to canvas\n",
    "\n",
    "pd.DataFrame(y_pred).to_csv(\"file.txt\",index = False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8580e34",
   "metadata": {},
   "source": [
    "## Calculate percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f43dde9-db98-4785-a049-9eb19a91cb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total values in CSV: 10000\n",
      "Number of matching values (order-sensitive): 6101\n",
      "Percentage of matching values: 61.01%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read values from CSV file without column names\n",
    "csv_file = 'EvaluationGT-2.csv'\n",
    "df = pd.read_csv(csv_file, header=None)\n",
    "\n",
    "# Grab the first column as a list\n",
    "csv_values = df.iloc[:, 0].tolist()\n",
    "\n",
    "# Step 2: Read values from the text file (assuming values are line-separated)\n",
    "text_file = 'file.txt'\n",
    "with open(text_file, 'r') as file:\n",
    "    text_values = [line.strip() for line in file.readlines()]  # Removing any extra spaces or newline chars\n",
    "\n",
    "# Step 3: Ensure both lists are the same length\n",
    "if len(csv_values) != len(text_values):\n",
    "    print(\"The CSV and text file do not have the same number of values.\")\n",
    "else:\n",
    "    # Step 4: Compare the values element-wise, considering the order\n",
    "    matches = [1 for csv_value, text_value in zip(csv_values, text_values) if csv_value == text_value]\n",
    "    \n",
    "    # Step 5: Calculate the percentage of matching values\n",
    "    num_matches = len(matches)\n",
    "    total_values = len(csv_values)\n",
    "    percentage_match = (num_matches / total_values) * 100\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Total values in CSV: {total_values}\")\n",
    "    print(f\"Number of matching values (order-sensitive): {num_matches}\")\n",
    "    print(f\"Percentage of matching values: {percentage_match:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
