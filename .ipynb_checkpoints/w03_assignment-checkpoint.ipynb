{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b208d4-57c3-498d-8a40-441c6b41646d",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "The task is to build and train a classifier given a labeled dataset and then use it to infer the labels of a given unlabeled evaluation dataset. \n",
    "\n",
    "You will find the training and evaluation data on canvas.\n",
    "\n",
    "Here's the training data: TrainOnMe-2.csv \n",
    "\n",
    "Here's the evaluation data: EvaluateOnMe-2.csv \n",
    "\n",
    "Here's the ground truth: EvaluationGT-2.csv\n",
    "\n",
    "You can use whatever python libraries you like! The steps below are suggestions, but feel free to try any other techniques we discussed in class.\n",
    "\n",
    "You can submit the predicted labels by uploading them in csv format, which will then be compared to the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3cf9a5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# For feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# For min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Some models you can try\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeca27-8629-4941-86c1-2d78c66ac582",
   "metadata": {},
   "source": [
    "## Load the training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25826ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "df = pd.read_csv('TrainOnMe-2.csv') \n",
    "eval_df = pd.read_csv('EvaluateOnMe-2.csv')\n",
    "\n",
    "# Split your training dataset into features and labels - Audrey Updated\n",
    "X = df.drop(columns=['y'])  # Features (all columns except Labels which is 'y' column)\n",
    "y = df['y']  # Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc8de1-a994-4756-9989-d3f4b0de1f0d",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96ac15-16cc-4702-bbd1-a19cbc8d216c",
   "metadata": {},
   "source": [
    "#### Remove NA values and noise - edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c95776a-27af-4777-8128-a1e9abf94a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with invalid outputs:\n",
      "                                    Unnamed: 0               y       x1  \\\n",
      "134               https://youtu.be/74TDvzZcHPw             NaN      NaN   \n",
      "307                                        306             NaN  1.12582   \n",
      "408                                        407             NaN  0.95125   \n",
      "581  Det är då som det stora vemodet rullar in             NaN      NaN   \n",
      "582            Och från havet blåser en isande   gråkall vind.      NaN   \n",
      "633                                        630             NaN  0.96981   \n",
      "739                                        736             NaN  0.61820   \n",
      "803          Den här är felt. Darfor erase it.             NaN      NaN   \n",
      "\n",
      "          x2       x3       x4        x5        x6                  x7  \\\n",
      "134      NaN      NaN      NaN       NaN       NaN                 NaN   \n",
      "307  0.37246 -3.91978 -8.69740   9.94560   0.38929     Jerry Fernström   \n",
      "408 -0.14534  2.69299 -9.22679  10.24097  -0.15571  Erik Sven Williams   \n",
      "581      NaN      NaN      NaN       NaN       NaN                 NaN   \n",
      "582      NaN      NaN      NaN       NaN       NaN                 NaN   \n",
      "633 -0.05689  1.91173 -9.37374  10.64983  -0.17658  Erik Sven Williams   \n",
      "739  0.19933 -4.66957 -9.47122  10.15735   0.16653     Jerry Fernström   \n",
      "803      NaN      NaN      NaN       NaN       NaN                 NaN   \n",
      "\n",
      "          x8       x9       x10      x11    x12       x13  \n",
      "134      NaN      NaN       NaN      NaN    NaN       NaN  \n",
      "307 -0.74363 -0.25968  -8.27133 -0.92003  False  54.33097  \n",
      "408 -0.80408  1.80860 -10.72584 -1.75732   True  48.90877  \n",
      "581      NaN      NaN       NaN      NaN    NaN       NaN  \n",
      "582      NaN      NaN       NaN      NaN    NaN       NaN  \n",
      "633 -1.62071  0.69365  -5.43491 -0.35794   True  49.44661  \n",
      "739  0.30113 -0.11972  -9.79420 -2.45160  False  28.57539  \n",
      "803      NaN      NaN       NaN      NaN    NaN       NaN  \n",
      "Row numbers removed due to invalid outputs: ['https://youtu.be/74TDvzZcHPw', '306', '407', 'Det är då som det stora vemodet rullar in', 'Och från havet blåser en isande', '630', '736', 'Den här är felt. Darfor erase it.']\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the training set - edited\n",
    "train_copy = df.copy()\n",
    "feature_copy = X.copy()\n",
    "\n",
    "# Removing the rows with y values that are not one of the four names\n",
    "valid_y_outputs = ['Bob', 'Jorg', 'Shoogee', 'Atsuto']\n",
    "invalid_rows = df[~df['y'].isin(valid_y_outputs)]\n",
    "print(\"Rows with invalid outputs:\")\n",
    "print(invalid_rows)\n",
    "# Store row numbers of invalid rows in a list\n",
    "removed_row_numbers = invalid_rows.iloc[:, 0].tolist()\n",
    "print(\"Row numbers removed due to invalid outputs:\", removed_row_numbers)\n",
    "# Remove the invalid rows from the DataFrame\n",
    "df_cleaned = df[df['y'].isin(valid_y_outputs)]\n",
    "\n",
    "# Removing the rows with missing values\n",
    "missing_rows = df[df.isnull().any(axis=1)]\n",
    "dropped_indices = missing_rows.index.tolist()\n",
    "df_cleaned = df.dropna()\n",
    "# Combine the list of missing value row numbers and invalid y outputs rows\n",
    "combined_removed_rows = list(set(removed_row_numbers + dropped_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882fd09e-b4b5-4856-9ab0-0b4916e461e9",
   "metadata": {},
   "source": [
    "#### Check the dtypes of all features - edited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e4536-7b82-488c-b0cd-e02caf5fd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dtypes of all features - edited \n",
    "print(df.dtypes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27937b-0ad8-4e49-ab75-1a0400499d17",
   "metadata": {},
   "source": [
    "#### Convert text columns to category - edited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66da102-5ff1-497b-bf82-046f6f4caf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the x7 column\n",
    "x7_cat = df[['x7']]\n",
    "x7_cat_encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "x7_encoded = encoder.fit_transform(x7_cat)\n",
    "x7_encoded_df = pd.DataFrame(x7_encoded, columns=encoder.get_feature_names_out(['x7'])) # Convert the result to a DataFrame\n",
    "x7_encoded_df.index = df.index  # Reset the index of the new DataFrame to match the original DataFrame\n",
    "df = df.drop('x7', axis=1)  # Drop the original 'x7' column from the DataFrame\n",
    "df = pd.concat([df, x7_encoded_df], axis=1)  # Concatenate the new one-hot encoded columns with the original DataFrame\n",
    "\n",
    "# Convert the x12 column\n",
    "df['x12'] = df['x12'].astype(int) # Convert True/False column to 1's and 0's\n",
    "\n",
    "# Change categories to encoded labels using LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad60bf-a533-4340-aabb-3d7a5c466e61",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "## Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccf3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to remove outliers from training data to improve performance\n",
    "# There are different ways to do this but one way could be to use stats.zscore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933a70d-7f5c-46cf-b278-536053c42322",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5a446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your features\n",
    "# You can try both standardscaler and minmaxscaler and see which works better\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f9ee0-f87c-4750-a328-dbdc9071fb07",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b35ae-3de7-4044-a59f-831a519ba36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could try to apply SelectKBest class to extract the most useful features (this is optional but MIGHT improve accuracy)\n",
    "# Remove whichever features that are not useful\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1dcc6-5f53-478d-9660-95368b4db961",
   "metadata": {},
   "source": [
    "## Split your data to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "2ed4f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cbcb0-c8ff-4d43-ab10-6c1e7d3aa0be",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "* You can try models other than the models listed below\n",
    "* You can try different hyperparameters\n",
    "* Evaluate your model using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ffb0a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Try linear SVM classifier\n",
    "linear = SVC(kernel='linear', C=0.5).fit(X_train, y_train)\n",
    "print(linear.score(X_test,y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(linear,X_test,y_test,cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53115ce",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Try decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion = \"gini\").fit(X_train, y_train)\n",
    "print(decision_tree.score(X_test,y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(decision_tree,X_test,y_test,cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01507d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try random forest classifier\n",
    "random_forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "print(random_forest.score(X_test,y_test))\n",
    "\n",
    "scores = cross_val_score(random_forest,X_test,y_test,cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your best model to predict the labels for the evaluation set\n",
    "\n",
    "y_pred = best_model.predict(X_eval)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "e6eb50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your predictions to a csv and upload it to canvas\n",
    "\n",
    "pd.DataFrame(y_pred).to_csv(\"file.txt\",index = False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab232a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64e303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
