{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b208d4-57c3-498d-8a40-441c6b41646d",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "The task is to build and train a classifier given a labeled dataset and then use it to infer the labels of a given unlabeled evaluation dataset. \n",
    "\n",
    "You will find the training and evaluation data on canvas.\n",
    "\n",
    "Here's the training data: TrainOnMe-2.csv \n",
    "\n",
    "Here's the evaluation data: EvaluateOnMe-2.csv \n",
    "\n",
    "Here's the ground truth: EvaluationGT-2.csv\n",
    "\n",
    "You can use whatever python libraries you like! The steps below are suggestions, but feel free to try any other techniques we discussed in class.\n",
    "\n",
    "You can submit the predicted labels by uploading them in csv format, which will then be compared to the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cf9a5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# For feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# For min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Some models you can try\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeca27-8629-4941-86c1-2d78c66ac582",
   "metadata": {},
   "source": [
    "## Load the training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25826ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "df = pd.read_csv('TrainOnMe-2.csv') \n",
    "eval_df = pd.read_csv('EvaluateOnMe-2.csv')\n",
    "\n",
    "# Split your training dataset into features and labels - Audrey Updated\n",
    "X = df.drop(columns=['y'])  # Features (all columns except Labels which is 'y' column)\n",
    "y = df['y']  # Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc8de1-a994-4756-9989-d3f4b0de1f0d",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96ac15-16cc-4702-bbd1-a19cbc8d216c",
   "metadata": {},
   "source": [
    "#### Remove NA values and noise - edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95776a-27af-4777-8128-a1e9abf94a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the training set - edited\n",
    "train_copy = df.copy()\n",
    "feature_copy = X.copy()\n",
    "\n",
    "# Removing the rows with y values that are not one of the four names\n",
    "# Force remove row 134\n",
    "df = df.drop(134) \n",
    "valid_y_outputs = ['Bob', 'Jorg', 'Shoogee', 'Atsuto']\n",
    "invalid_rows = df[~df['y'].isin(valid_y_outputs)]\n",
    "print(\"Rows with invalid outputs:\")\n",
    "print(invalid_rows)\n",
    "\n",
    "# Store row indices of invalid rows in a list\n",
    "removed_row_numbers = invalid_rows.index.tolist()\n",
    "print(\"Row indices removed due to invalid outputs:\", removed_row_numbers)\n",
    "\n",
    "# Remove the invalid rows from the DataFrame\n",
    "df_y = df[df['y'].isin(valid_y_outputs)]\n",
    "\n",
    "# Remove rows that do not have a valid row number in the first column\n",
    "first_column = df_y.columns[0]\n",
    "# Convert to numeric, forcing errors to NaN, and then drop rows with NaN\n",
    "df_y.loc[:, first_column] = pd.to_numeric(df_y[first_column], errors='coerce')\n",
    "\n",
    "# Identify rows with non-numeric values in the first column\n",
    "non_numeric_rows = df_y[df_y[first_column].isna()]\n",
    "non_numeric_indices = non_numeric_rows.index.tolist()\n",
    "# Remove rows with non-numeric values\n",
    "df_0 = df_y.dropna(subset=[first_column])\n",
    "\n",
    "# Removing the rows with missing values\n",
    "missing_rows = df_0[df_0.isnull().any(axis=1)]\n",
    "dropped_indices = missing_rows.index.tolist()\n",
    "df_cleaned = df_0.dropna()\n",
    "\n",
    "# Combine the list of removed indices\n",
    "combined_removed_rows = list(set(removed_row_numbers + dropped_indices + non_numeric_indices))\n",
    "print(\"Combined row indices removed:\", combined_removed_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882fd09e-b4b5-4856-9ab0-0b4916e461e9",
   "metadata": {},
   "source": [
    "#### Check the dtypes of all features - edited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e4536-7b82-488c-b0cd-e02caf5fd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dtypes of all features - edited \n",
    "print(df.dtypes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27937b-0ad8-4e49-ab75-1a0400499d17",
   "metadata": {},
   "source": [
    "#### Convert text columns to category - edited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66da102-5ff1-497b-bf82-046f6f4caf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the 'x7' column\n",
    "print(\"Missing values in 'x7':\", df_cleaned['x7'].isna().sum())\n",
    "\n",
    "# Drop rows with missing values in 'x7'\n",
    "df_cleaned = df_cleaned.dropna(subset=['x7'])\n",
    "\n",
    "# Convert the x7 column using OneHotEncoder\n",
    "x7_cat = df_cleaned[['x7']]\n",
    "x7_cat_encoder = OneHotEncoder(sparse_output=False, drop='first')  # Use sparse_output instead of sparse\n",
    "x7_encoded = x7_cat_encoder.fit_transform(x7_cat)\n",
    "x7_encoded_df = pd.DataFrame(x7_encoded, columns=x7_cat_encoder.get_feature_names_out(['x7'])) \n",
    "\n",
    "# Ensure the index lengths match before assigning\n",
    "if len(x7_encoded_df) == len(df_cleaned):\n",
    "    x7_encoded_df.index = df_cleaned.index  # Reset the index to match the original DataFrame\n",
    "else:\n",
    "    print(\"Warning: Mismatch in the number of rows after encoding 'x7'\")\n",
    "\n",
    "# Drop the original 'x7' column and concatenate the encoded columns\n",
    "df_cleaned = df_cleaned.drop('x7', axis=1)\n",
    "df_cleaned = pd.concat([df_cleaned, x7_encoded_df], axis=1)\n",
    "\n",
    "# Convert the x12 column\n",
    "df_cleaned['x12'] = df_cleaned['x12'].astype(int)  # Convert True/False column to 1's and 0's\n",
    "\n",
    "# Attempt to convert x6 to numeric, coercing errors to NaN\n",
    "df_cleaned['x6'] = pd.to_numeric(df_cleaned['x6'], errors='coerce')\n",
    "# Check if there are any NaN values after the conversion\n",
    "non_numeric_x6 = df_cleaned[df_cleaned['x6'].isna()]\n",
    "print(\"Rows with non-numeric values in 'x6':\")\n",
    "print(non_numeric_x6)\n",
    "# Fill in non-numeric x6\n",
    "df_cleaned['x6'].fillna(df_cleaned['x6'].median(), inplace=True)\n",
    "\n",
    "# Convert the first column to numeric, coercing errors to NaN\n",
    "df_cleaned[df_cleaned.columns[0]] = pd.to_numeric(df_cleaned[df_cleaned.columns[0]], errors='coerce')\n",
    "# Compute the median of the column, ignoring NaN values\n",
    "median_value = df_cleaned[df_cleaned.columns[0]].median()\n",
    "# Fill NaN values with the median value\n",
    "df_cleaned[df_cleaned.columns[0]].fillna(median_value, inplace=True)\n",
    "\n",
    "# Check the types and information of the DataFrame\n",
    "print(df_cleaned.dtypes)\n",
    "df_cleaned.info()\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_cols = df_cleaned.select_dtypes(exclude=[np.number]).columns\n",
    "print(f\"Non-numeric columns: {non_numeric_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad60bf-a533-4340-aabb-3d7a5c466e61",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "## Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you only use numeric columns for Z-score calculation\n",
    "numeric_df = df_cleaned.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate Z-scores for each column in df_cleaned, which ensures index alignment\n",
    "z_scores = np.abs(stats.zscore(numeric_df))\n",
    "\n",
    "# Define a threshold for Z-scores\n",
    "z_threshold = 3\n",
    "\n",
    "# Identify rows that have any Z-score above the threshold\n",
    "outliers = (z_scores > z_threshold).any(axis=1)\n",
    "\n",
    "# Ensure the index of 'outliers' matches df_cleaned\n",
    "outliers = outliers.reindex(df_cleaned.index, fill_value=False)\n",
    "\n",
    "# Print the rows with outliers\n",
    "outlier_rows = df_cleaned[outliers]\n",
    "print(\"Rows with outliers:\")\n",
    "print(outlier_rows)\n",
    "\n",
    "# Remove outliers from df_cleaned\n",
    "df_cleaned = df_cleaned[~outliers]\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(\"\\nDataFrame after removing outliers:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "# There are different ways to do this but one way could be to use stats.zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933a70d-7f5c-46cf-b278-536053c42322",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your features\n",
    "# You can try both standardscaler and minmaxscaler and see which works better - edited\n",
    "# ONLY USE NUMERICAL\n",
    "data_num = df_cleaned.select_dtypes(include=['number']) \n",
    "std_scaler = StandardScaler()\n",
    "data_num_std_scaled = std_scaler.fit_transform(data_num)\n",
    "\n",
    "# Test if Standard Scaled worked\n",
    "scaled_df = pd.DataFrame(data_num_std_scaled, columns=data_num.columns, index=df_cleaned.index)\n",
    "\n",
    "# Check mean and standard deviation\n",
    "means = scaled_df.mean()\n",
    "std_devs = scaled_df.std()\n",
    "\n",
    "print(\"Means of scaled features:\")\n",
    "print(means)\n",
    "print(\"\\nStandard deviations of scaled features:\")\n",
    "print(std_devs)\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_cols = df_cleaned.select_dtypes(exclude=[np.number]).columns\n",
    "print(f\"Non-numeric columns: {non_numeric_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f9ee0-f87c-4750-a328-dbdc9071fb07",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b35ae-3de7-4044-a59f-831a519ba36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could try to apply SelectKBest class to extract the most useful features (this is optional but MIGHT improve accuracy)\n",
    "# Remove whichever features that are not useful\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1dcc6-5f53-478d-9660-95368b4db961",
   "metadata": {},
   "source": [
    "## Split your data to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-numeric columns\n",
    "non_numeric_cols = df_cleaned.select_dtypes(exclude=[np.number]).columns\n",
    "print(f\"Non-numeric columns: {non_numeric_cols}\")\n",
    "\n",
    "X = df_cleaned.drop(columns=['y'])  # Drop the target column to get features\n",
    "y= df_cleaned['y']  # Extract the target variable\n",
    "\n",
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state = 0)\n",
    "\n",
    "# Check for non-numeric columns in X_train\n",
    "non_numeric_columns = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "print(\"Non-numeric columns in X_train:\", non_numeric_columns)\n",
    "\n",
    "# Check for non-numeric values in each column\n",
    "for col in X_train.columns:\n",
    "    non_numeric = X_train[X_train[col].apply(lambda x: not isinstance(x, (int, float)))]\n",
    "    if not non_numeric.empty:\n",
    "        print(f\"Non-numeric values in column {col}:\")\n",
    "        print(non_numeric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cbcb0-c8ff-4d43-ab10-6c1e7d3aa0be",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "* You can try models other than the models listed below\n",
    "* You can try different hyperparameters\n",
    "* Evaluate your model using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ffb0a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Try linear SVM classifier\n",
    "linear = SVC(kernel='linear', C=0.5).fit(X_train, y_train)\n",
    "print(linear.score(X_test,y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(linear,X_test,y_test,cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53115ce",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Try decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion = \"gini\").fit(X_train, y_train)\n",
    "print(decision_tree.score(X_test,y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(decision_tree,X_test,y_test,cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01507d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try random forest classifier\n",
    "random_forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "print(random_forest.score(X_test,y_test))\n",
    "\n",
    "scores = cross_val_score(random_forest,X_test,y_test,cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3b68b7fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[316], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use your best model to predict the labels for the evaluation set\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_eval)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Use your best model to predict the labels for the evaluation set\n",
    "\n",
    "y_pred = best_model.predict(X_eval)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your predictions to a csv and upload it to canvas\n",
    "\n",
    "pd.DataFrame(y_pred).to_csv(\"file.txt\",index = False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43dde9-db98-4785-a049-9eb19a91cb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
